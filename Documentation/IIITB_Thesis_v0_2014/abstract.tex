% abstract.tex
\begin{center}
\textbf{\Large VISIBILITY DRIVEN FOCUS+CONTEXT VISUALIZATION } \\
\vspace{0.5cm}
\textbf{\Large OF MULTIMODAL VOLUME DATA} \\
\vspace{2.0cm}
\textbf{\large Abstract}
\vspace{1.0cm}
\end{center}


The aim of this thesis is to study mechanisms to improve focus+context visualization of multimodal volumetric data. Specifically, the use of visibility histograms is investigated. Visibility histograms provide intuitive cues to the user (or the visualization application) about the contribution of particular scalar values to the final image.  These cues are view dependent, and can be used to redesign transfer functions such that the visibility of regions of interest is improved, while maintaining surrounding context. We also use per-ray visibility histograms, which provides additional tools to examine multimodal volume data. â€‹The technique uses a ray tracing approach, and is applied to both single modality as well as dual modality data. The solution has been implemented on the GPU, to enable interactive response. The technique is demonstrated on multimodal data -  CT and PET - to produce fused focus+context volume visualization, with focus on PET data, while the CT dataset provides clear contextual information. 


